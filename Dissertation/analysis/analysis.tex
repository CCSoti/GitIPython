The research paper is connected with an area of study, called Mining Software Repositories (MSR)\cite{MSR2016}, that is growing together with the massive amount of available software repositories. Its purpose is to investigate and create relationships between the repository data items in order to find unique and useful information about a particular software system and, also, optimize the work that needs to be done during the analysis. Researchers and software developers use their own experience and knowledge for repository investigation and they tend to concentrate on a particular part of the code, e.g. testers usually are focusing on features errors and bugs. However, this might lead to faulty and ineffective results. MSR is an approach for overcoming this problem, it is analysing into great detail repositories and it is building complex models between data items\cite{hassan2008road}. IPython Observatory project is covering ideas and aspects that MSR is looking to achieve, with the difference that only a specific group of repositories are analysed - projects connected with IPython Notebook.

\subsection{GitHub limitations and data extraction}
\label{subsec:limitations}
The first part of the project is consisting of the creation of methods and techniques for the extraction of data from GitHub\cite{gitHubWiki} and the its limitations. Mining Software Repository field is concerned with the automation of gathering data from hosts such as GitHub. Two major problems that MSR is encountering are\cite{hassan2008road}:

\vspace{1em}
\begin{description}
    \item[Limited Access to Repositories]  Not all of the repositories are public, which means that they are available for everyone. Companies that are using GitHub as a version control service for their code are not interested of sharing details about their software systems, which makes research projects less effective since they can not access richer and more complex project than those that have less contributors and features\cite{hassan2008road}. 
    
    \item[Complexity of Data Extraction] A lot of time, effort and software knowledge is required to extract data from repositories. The new GitHub API (Application programming interface)\cite{GitAPI} is allowing access to a huge amount of repositories data. However, it has limitations for copying data and not all repository features are present. 
\end{description}
\vspace{1em}

IPython Observatory project faced the same limitations together with the collection of repositories that contain IPython Notebook scripts. Its prototype is extracting repositories that are containing the word \textit{IPython} with the help of the GitHub Search API\cite{GitAPISearch}, which sends and receives data as JSON\cite{json}. However, not all of search results are containing IPython scripts - that is an aspect that is considered in the research prototype. All of the analysis, explained in the next subsections, are done on repositories that have at least one IPython script. Also, the number and the content of repositories containing the word IPython are constantly changing - on November 2015 the number is 3933 and on March 2016 - 4492, which states that the usage of GitHub and IPython Notebook has increased in six months. The project's prototype is extracting data from the GitHub API and it is not tracking changes in time, which might be implemented as a future functionality.

Furthermore, the GitHub API is showing projects that are only publicly accessible. Analysis over repositories that have a huge number of commits and contributors are more likely to represent high quality of work and accuracy of results. The project encounters limitations with the extraction of data - Search GitHub API "provides up to 1,000 results for each search"\cite{GitAPISearch}, "for unauthenticated requests, the rate limit allows you to make up to 10 requests per minute"\cite{GitAPISearch} and the rate limit of the GitHub API is "60 requests per hour"\cite{GitAPI}. The prototype is downloading 866 repositories that contain the word "IPython" by an algorithm that is waiting a curtain amount of time on the ninth and fifty-ninth cloned repository. A future work for the project might overcome the GitHub API limitations and being able to analyse over all existing search results. 

The technique, used in the research prototype for extraction of data, is extracting the GitHub API JSON representation and it stores it into a file. Eaxh GitHub repository has url, which was used for cloning the projects. Python was used as a programming language for the code. The Python package GitPython\cite{GitPython} provides object model access to git repositories and it was used for cloning and analysing them. The limitations with the requests is handled by waiting 30 seconds on each ninth downloaded repository and waiting 30 minutes on every fifty-ninth downloaded repository. Since the GitHub API shows information only for one page of search results, the prototype is traversing through 10 pages(each page can contain 30 or 100 results, and the code set the parameter for that to 100) by changing a parameter in the search url. 

Finally, another issue that might be encountered during the extraction of information is storage. The amount of data of the all the cloned repositories is 19GB. University of Glasgow has provided a server for the research project, that takes up to 90GB of data. 

To sum up, this stage of the project overcame the issues and limitations encountered with access, collection, amount and storage of specific group of repositories. Two approaches for future work are suggested - tracking changes and quality of data in time and extraction of all search results.

\subsection{Mining Repository's information}
\label{subsec:mining}

A lot of researchers are analysing the usage of programming tools on GitHub and what effect does the version control hosting site has on the improvement of software systems. The Kalliamvakou's paper \cite{kalliamvakoupromises} is investigating possible threats to the validity of researches involving software projects hosted on GitHub. They can be viewed as fundamental steps for analysing all of the repositories connected with IPython notebooks. Figure \ref{fig:perils} is showing the results of the paper. In the paper are described thirteen perils that pose potential threats to validity for studies involving software projects hosted in GitHub. Instead of accepting these repository's perils as aspects that need to be avoid, IPython Observatory is investigating them and reporting the results for the usage of IPython in GitHub. This section describes the steps taken for the analysis made on repositories' features.

\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{1}:}  A repository is not necessarily a project
\vspace{1px}
\end{mdframed}
\vspace{2mm}

As described in the Kalliamvako's paper\cite{kalliamvakoupromises}, GitHub is using the pull request development model for collaboration in a software development project. It is accepted that contributors are not making any changes into the main repository of the project and they are cloning the repository and making changes without interfering with others work. All of the new and changed files of repository are stored in a local branch, which later is inspected and pulled into the master branch by a member of the project's core team. After a code review, the contributors need to update their local branches with the new commits. This model represents repositories as base and fork repositories - respectively, the main repositories and those that are independently recording activities. Only the commits in the base repositories are tracked, which means that non-merged ones will be ignored.

The technique used in IPython Observatory for identifying if a repository is a project, is extracting all merges made into the repository. GitPython was used for the process and each merge in the package has a name and a stage, which represents conflicts during the merging. If a stage is zero then there were no conflicts, else - there were conflicts in the merge. Then the prototype is traversing through each merges' stage and calculating the percentage of merges without any conflicts against the number of all merges. However, when the code was executed on the extracted 866 repositories and it returned a value of 1.0, which means that all of the merges in the repositories have no conflicts. The algorithm could be improved and investigated even further as a future task. 

\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{2}:}  Most projects have low activity
\vspace{1px}
\end{mdframed}
\vspace{2mm}

One of the most crucial features of GitHub repositories are the commits - 20 times more than pull request and issues\cite{kalliamvakoupromises}. Kalliamvako's paper\cite{kalliamvakoupromises} suggests that GitHub repository's activity can be measured with the number of commits and the time of commits, which tracks the lifespan of a project. This will indicate the work done for the project and its usage on GitHub.

---> Mine

\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{3}:}  Most projects are inactive
\vspace{1px}
\end{mdframed}
\vspace{2mm}

This aspect is closely connected with the previous one - Aspect \RNum{2}. It is considered that if a project has a small number of commits, it would have limited functionality and it is inactive. 

---> Mine

\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{4}:}  Many projects are not software development
\vspace{1px}
\end{mdframed}
\vspace{2mm}

Kalliamvako's survey\cite{kalliamvakoupromises} reports that GitHub repositories are not only used for software developement projects - 14\% respondents (out of 240) are using GitHub for experimentation's and academic/class projects and 10\% are using it for storage. IPython Observatory's idea originates from the idea that GitHub repositories are used for various purposes - e.g. storing IPython notebooks for teaching, learning and organizational purposes. 

IPython Observatory is is analysing two aspects of a repository in order to identify the usage of IPython - languages used in a repository - types of files and whether a repository has a README file or similar describtion file. One more aspect to be considered for future implementations might be the content of a README file - implementing an algorithm for identifying the aim of the project explained in the README file. 

---> Mine

If a repository is used for only storage purposes, it might only has few number of commits and a small lifespan. This contradicts with the statement that we made above - if a project has small amount of commits then it is more likely to be inactive. A future implementation for analysis could be the creation of a model between these two aspects or any other two aspects - Aspect \RNum{3} and Aspect \RNum{4} paragraphs.


\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{5}:}  Most projects are personal
\vspace{1px}
\end{mdframed}
\vspace{2mm}

A GitHub repository might have one or several contributors - it could be used not only for collaboration, but also for personal use, which connects with the idea mentioned in Aspect \RNum{4}, that some projects might be used only for storage. Kalliamvako's survey\cite{kalliamvakoupromises} reports that 38\% out of 240 respondents use GitHub mainly for their own projects and they don't have the intention of collaborating with others. The result are an motivating factor for analysis over the collaboration and social interaction in IPython Notebook's projects. IPython Observatoiry evaluates if a project is
personal by counting the number of different committers in all the collected repositories.

These results indicate --> Mine

Also, the Kalliamvako's survey\cite{kalliamvakoupromises} results show that most of the projects on GitHub are used by only one person, most likely for experimental or storage purposes. An idea for analysis over the relation between the usage of IPython projects for personal use and all repositories on GitHub for personal used, might be implemented as a future improvement.


\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{6}:}  Many active projects do not use GitHub exclusively
\vspace{1px}
\end{mdframed}
\vspace{2mm}

GitHub allows contributes on a project not only for registered users. Analysis over the type of contributors of a project indicates areas of usage for a specific project. IPython Observatory has chosen GitHub as the most popular and changing source of information, but there might be others. There are two aspects that helps with the investigation over this aspect and they could be considered as future work - survey of users using both IPython and a host service, and analysis over the names of the contributors in a specific IPython project - if a non GitHub user made a commit, then GitHub records an email address as their work\cite{kalliamvakoupromises}. Kalliamvako's survey\cite{kalliamvakoupromises} concludes that there is a huge number of projects, which activities are not conducted within GitHub.

\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{7}:}  Many active projects do not use GitHub exclusively
\vspace{1px}
\end{mdframed}
\vspace{2mm}

Kalliamvako's paper\cite{kalliamvakoupromises} reports that personal projects, which are 67\% from all of the projects, amd they are not using pull requests. This aspect is connected with Aspect \RNum{7} and it could use the same approach for analysis and include one more functionality - number of pull requests, since personal projects should have zero pull requests.

\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{8}:}  Merges only track successful code
\vspace{1px}
\end{mdframed}
\vspace{2mm}

The peer review model on GitHub has a disadvantage for the project's commits - they might not be readily-observable. This means that usually, all the commits are reviewed and merged within the main repository as one. The GItHub API\cite{gitHubAPI} is recording only the final stage and not all of the original commits. As a consequence, researchers can only observe the latest commit, which is the outcome of the code review process\cite{kalliamvakoupromises}.

IPython Observatory is analysing through this aspect of a repository by extracting all merges that are accessible for a repository. It is closely connected with Aspect \RNum{9}.

---> Mine

\vspace{5mm}
\begin{mdframed}
\vspace{1px}
\textbf{Aspect \RNum{9}:}  Many merged pull requests appear as non-merged.
\vspace{1px}
\end{mdframed}
\vspace{2mm}

Merged pull requests might be merged outside GitHub, as explained in Aspect \RNum{8}. Kalliamvako's paper\cite{kalliamvakoupromises} has developed a heuristics based on conventions advocated by GitHub. Creation of a prototype that implements these heuristics might be considered as a future work and it will contribute to the field of Mining Software Repositories(MSR)\cite{MSR2016}.

\vspace{8mm}

Aspects \RNum{10}, \RNum{11} are closely connected with Aspect \RNum{6}. IPython Observatory has conducted analysis over number of contributors for a specific project. They can be extended into a lot more complex models and into software tools that implement the models. 

Aspects \RNum{12}, \RNum{13} are specific for the Kalliamvako's paper\cite{kalliamvakoupromises}. They are suggested analysis over the whole information that can extracted from GitHub. With respect to IPython projects, Aspects \RNum{12}, \RNum{13} might be understood as points that are covered in \ref{subsec:limitations}.


\input{analysis/scientific_method/main.tex}

